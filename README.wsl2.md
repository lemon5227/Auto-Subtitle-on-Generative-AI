# WSL2 ç¯å¢ƒéƒ¨ç½²æŒ‡å—

WSL2 (Windows Subsystem for Linux 2) ç¯å¢ƒä¸‹çš„ AI å­—å¹•ç”Ÿæˆå™¨éƒ¨ç½²å®Œå…¨æŒ‡å—ã€‚

## ğŸ–¥ï¸ WSL2 ç¯å¢ƒè¯´æ˜

WSL2 æä¾›äº†åœ¨ Windows ä¸Šè¿è¡Œ Linux ç¯å¢ƒçš„èƒ½åŠ›ï¼Œä½† GPU æ”¯æŒéœ€è¦ç‰¹æ®Šé…ç½®ã€‚

### ç³»ç»Ÿè¦æ±‚
- **Windows 11** æˆ– **Windows 10** (ç‰ˆæœ¬ 21H2 æˆ–æ›´é«˜)
- **WSL2** å·²å®‰è£…å¹¶å¯ç”¨
- **Ubuntu 20.04+** æˆ– **Debian 11+** (æ¨è Ubuntu 22.04)
- å†…å­˜ï¼šè‡³å°‘ 8GB RAM (æ¨è 16GB+)
- **å¯é€‰**: NVIDIA GPU (RTX 20/30/40 ç³»åˆ—)

## ğŸš€ æ–¹æ³•ä¸€ï¼šWSL2 ä¸€é”®éƒ¨ç½²è„šæœ¬

### è¶…çº§ç®€å•ä¸€é”®å®‰è£…

```bash
# åœ¨ WSL2 Ubuntu ç¯å¢ƒä¸­è¿è¡Œ
curl -fsSL https://raw.githubusercontent.com/lemon5227/Auto-Subtitle-on-Generative-AI/main/install-wsl2.sh | bash
```

## ğŸ› ï¸ æ–¹æ³•äºŒï¼šæ‰‹åŠ¨è¯¦ç»†éƒ¨ç½²

### æ­¥éª¤ 1: å‡†å¤‡ WSL2 ç¯å¢ƒ

#### 1.1 å®‰è£… WSL2 (åœ¨ Windows PowerShell ç®¡ç†å‘˜æ¨¡å¼)
```powershell
# å¯ç”¨ WSL åŠŸèƒ½
dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart
dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart

# é‡å¯ Windows åç»§ç»­
wsl --set-default-version 2

# å®‰è£… Ubuntu 22.04
wsl --install -d Ubuntu-22.04
```

#### 1.2 é…ç½® WSL2 èµ„æºé™åˆ¶
åœ¨ Windows ç”¨æˆ·ç›®å½•ä¸‹åˆ›å»º `.wslconfig` æ–‡ä»¶ï¼š

```ini
# C:\Users\<YourUsername>\.wslconfig
[wsl2]
memory=8GB          # åˆ†é…ç»™ WSL2 çš„å†…å­˜
processors=4        # CPU æ ¸å¿ƒæ•°
swap=2GB           # äº¤æ¢æ–‡ä»¶å¤§å°
localhostForwarding=true
```

é‡å¯ WSL2ï¼š
```bash
# åœ¨ Windows CMD/PowerShell ä¸­
wsl --shutdown
wsl
```

### æ­¥éª¤ 2: WSL2 ç³»ç»Ÿä¾èµ–å®‰è£…

#### 2.1 æ›´æ–°ç³»ç»Ÿ
```bash
# åœ¨ WSL2 Ubuntu ä¸­è¿è¡Œ
sudo apt update && sudo apt upgrade -y
```

#### 2.2 å®‰è£…åŸºç¡€å·¥å…·
```bash
# å®‰è£…ç³»ç»Ÿä¾èµ–
sudo apt install -y \
    python3 python3-pip python3-venv \
    git curl wget \
    ffmpeg \
    build-essential \
    software-properties-common
```

#### 2.3 å®‰è£… Python ç¯å¢ƒç®¡ç†
```bash
# å®‰è£… conda (æ¨è)
curl -fsSL https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -o miniconda.sh
bash miniconda.sh -b -p $HOME/miniconda
echo 'export PATH="$HOME/miniconda/bin:$PATH"' >> ~/.bashrc
source ~/.bashrc
rm miniconda.sh
```

### æ­¥éª¤ 3: WSL2 GPU æ”¯æŒé…ç½® â­ æ ¸å¿ƒç‰¹æ€§

> ğŸ’¡ **WSL2 GPU æ”¯æŒçš„ç‹¬ç‰¹ä¼˜åŠ¿**: æ— éœ€åœ¨ Linux ä¸­å®‰è£… CUDAï¼Œé€šè¿‡ Windows é©±åŠ¨å³å¯è·å¾—å®Œæ•´ GPU åŠ é€Ÿï¼

#### 3.1 æ£€æŸ¥ Windows ç«¯ NVIDIA é©±åŠ¨
```powershell
# åœ¨ Windows PowerShell ä¸­æ£€æŸ¥
nvidia-smi
```

**ğŸ¯ é©±åŠ¨ç‰ˆæœ¬è¦æ±‚:**
- âœ… **æ¨è**: NVIDIA é©±åŠ¨ >= 470.76 (æ”¯æŒ CUDA 11.4+)
- â­ **æœ€ä½³**: NVIDIA é©±åŠ¨ >= 516.xx (æ”¯æŒ CUDA 11.7+) 
- ğŸš€ **ç†æƒ³**: æœ€æ–°ç‰ˆæœ¬é©±åŠ¨ (è·å¾—æœ€ä½³å…¼å®¹æ€§)

**ğŸ“¥ é©±åŠ¨æ›´æ–°æ–¹æ³•:**
1. è®¿é—® [NVIDIA å®˜ç½‘](https://www.nvidia.com/drivers) ä¸‹è½½æœ€æ–°é©±åŠ¨
2. æˆ–ä½¿ç”¨ GeForce Experience è‡ªåŠ¨æ›´æ–°
3. æ›´æ–°åé‡å¯ Windows ç³»ç»Ÿ

#### 3.2 WSL2 CUDA æ”¯æŒåŸç† â­ é‡è¦
âš ï¸ **å…³é”®ä¿¡æ¯**: WSL2 ç¯å¢ƒä¸‹çš„ CUDA æ”¯æŒæœºåˆ¶ï¼š

**âœ… åªéœ€è¦ï¼ˆWindows ç«¯ï¼‰:**
- âœ… æœ€æ–°çš„ NVIDIA é©±åŠ¨ç¨‹åºï¼ˆç‰ˆæœ¬ 470.76 æˆ–æ›´é«˜ï¼‰
- âœ… Windows ç«¯é©±åŠ¨è‡ªå¸¦ CUDA è¿è¡Œæ—¶æ”¯æŒ

**âŒ ä¸éœ€è¦ï¼ˆWSL2 å†…éƒ¨ï¼‰:**
- âŒ **ä¸è¦**åœ¨ WSL2 ä¸­å®‰è£… CUDA Toolkit
- âŒ **ä¸è¦**å®‰è£… cuDNN
- âŒ **ä¸è¦**é…ç½® CUDA ç¯å¢ƒå˜é‡

**ğŸ”§ å·¥ä½œåŸç†:**
Windows NVIDIA é©±åŠ¨é€šè¿‡ `/usr/lib/wsl/lib/` ç›®å½•å‘ WSL2 æä¾› CUDA åº“æ–‡ä»¶ï¼Œå®ç°æ— ç¼GPUåŠ é€Ÿã€‚

#### 3.3 éªŒè¯ GPU æ”¯æŒ
```bash
# åœ¨ WSL2 ä¸­æ£€æŸ¥
ls -la /usr/lib/wsl/lib/
# åº”è¯¥çœ‹åˆ° libcuda.so, libcudart.so ç­‰æ–‡ä»¶
```

### æ­¥éª¤ 4: éƒ¨ç½²åº”ç”¨

#### 4.1 å…‹éš†é¡¹ç›®
```bash
cd ~
git clone https://github.com/lemon5227/Auto-Subtitle-on-Generative-AI.git
cd Auto-Subtitle-on-Generative-AI
```

#### 4.2 åˆ›å»º Python ç¯å¢ƒ
```bash
# ä½¿ç”¨ conda åˆ›å»ºç¯å¢ƒ
conda create -n whisper-app python=3.11 -y
conda activate whisper-app
```

#### 4.3 å®‰è£… PyTorch (WSL2 ä¸“ç”¨é…ç½®)

**ğŸ¯ WSL2 æ™ºèƒ½ PyTorch å®‰è£…:**
```bash
# WSL2 æ¨èæ–¹å¼ï¼šè®©è„šæœ¬è‡ªåŠ¨é€‰æ‹©ç‰ˆæœ¬
python -c "
import subprocess
import os

# æ£€æŸ¥ WSL GPU åº“
has_wsl_gpu = os.path.exists('/usr/lib/wsl/lib/libcuda.so.1')

if has_wsl_gpu:
    print('ğŸ® æ£€æµ‹åˆ° WSL GPU æ”¯æŒï¼Œå®‰è£… CUDA ç‰ˆæœ¬...')
    subprocess.run(['pip', 'install', 'torch', 'torchvision', 'torchaudio', 
                   '--index-url', 'https://download.pytorch.org/whl/cu118'])
else:
    print('ğŸ’» æœªæ£€æµ‹åˆ° GPU æ”¯æŒï¼Œå®‰è£… CPU ç‰ˆæœ¬...')
    subprocess.run(['pip', 'install', 'torch', 'torchvision', 'torchaudio', 
                   '--index-url', 'https://download.pytorch.org/whl/cpu'])
"
```

**ğŸ”§ æ‰‹åŠ¨å®‰è£…é€‰æ‹©:**
```bash
# æœ‰GPUæ”¯æŒæ—¶ï¼ˆæ¨èï¼‰
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# ä»…CPUæ¨¡å¼æ—¶
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
```

#### 4.4 å®‰è£…åº”ç”¨ä¾èµ–
```bash
pip install -r requirements.txt
```

#### 4.5 éªŒè¯ WSL2 GPU æ”¯æŒ
```bash
# å®Œæ•´çš„ WSL2 GPU éªŒè¯è„šæœ¬
python -c "
import torch
import os

print('ğŸ” WSL2 GPU ç¯å¢ƒæ£€æŸ¥')
print('-' * 40)

# æ£€æŸ¥ WSL GPU åº“æ–‡ä»¶
wsl_cuda_lib = '/usr/lib/wsl/lib/libcuda.so.1'
print(f'WSL CUDA åº“: {'âœ… å­˜åœ¨' if os.path.exists(wsl_cuda_lib) else 'âŒ ä¸å­˜åœ¨'}')

if os.path.exists('/usr/lib/wsl/lib/'):
    import glob
    wsl_libs = glob.glob('/usr/lib/wsl/lib/*cuda*') + glob.glob('/usr/lib/wsl/lib/*nv*')
    print(f'WSL GPU åº“æ•°é‡: {len(wsl_libs)}')

# PyTorch CUDA æ£€æŸ¥
print(f'PyTorch ç‰ˆæœ¬: {torch.__version__}')
print(f'CUDA å¯ç”¨: {'âœ… æ˜¯' if torch.cuda.is_available() else 'âŒ å¦'}')

if torch.cuda.is_available():
    print(f'GPU æ•°é‡: {torch.cuda.device_count()}')
    print(f'GPU å‹å·: {torch.cuda.get_device_name(0)}')
    print(f'CUDA ç‰ˆæœ¬: {torch.version.cuda}')
    
    # ç®€å•æµ‹è¯•
    try:
        x = torch.randn(100, 100).cuda()
        y = torch.matmul(x, x)
        print('GPU è®¡ç®—æµ‹è¯•: âœ… é€šè¿‡')
        del x, y
        torch.cuda.empty_cache()
    except Exception as e:
        print(f'GPU è®¡ç®—æµ‹è¯•: âŒ å¤±è´¥ - {e}')
else:
    print('å»ºè®®æ£€æŸ¥:')
    print('1. Windows NVIDIA é©±åŠ¨ç‰ˆæœ¬æ˜¯å¦ >= 470.76')
    print('2. WSL2 æ˜¯å¦æ­£ç¡®å®‰è£…')
    print('3. é‡å¯ WSL2: wsl --shutdown && wsl')
"
```

### æ­¥éª¤ 5: å¯åŠ¨æœåŠ¡

#### 5.1 å¯åŠ¨åº”ç”¨
```bash
# æ¿€æ´»ç¯å¢ƒ
conda activate whisper-app

# å¯åŠ¨æœåŠ¡
python app.py
```

#### 5.2 è®¿é—®åº”ç”¨
åœ¨ Windows æµè§ˆå™¨ä¸­è®¿é—®ï¼š
- **å®æ—¶è½¬å½•**: http://localhost:5001/realtime.html  
- **æ–‡ä»¶å¤„ç†**: http://localhost:5001/app.html

## ğŸ”§ WSL2 ç‰¹æ®Šé…ç½®å’Œä¼˜åŒ–

### GPU å†…å­˜ä¼˜åŒ–
```bash
# è®¾ç½®ç¯å¢ƒå˜é‡é¿å… CUDA å†…å­˜é—®é¢˜
echo 'export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128' >> ~/.bashrc
echo 'export CUDA_LAUNCH_BLOCKING=1' >> ~/.bashrc
source ~/.bashrc
```

### åˆ›å»º WSL2 ä¸“ç”¨å¯åŠ¨è„šæœ¬
```bash
cat > start_wsl2.py << 'EOF'
#!/usr/bin/env python3
"""
WSL2 ä¸“ç”¨å¯åŠ¨è„šæœ¬ - è§£å†³ WSL2 ç¯å¢ƒç‰¹æ®Šé—®é¢˜
"""
import os
import sys
import subprocess

# WSL2 ç¯å¢ƒä¼˜åŒ–
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'

print("ğŸ”§ WSL2 ä¼˜åŒ–å¯åŠ¨å™¨")
print("ğŸš€ é’ˆå¯¹ WSL2 ç¯å¢ƒä¼˜åŒ–çš„ AI å­—å¹•ç”Ÿæˆå™¨")
print("-" * 50)

# æ£€æŸ¥ WSL2 ç¯å¢ƒ
if 'microsoft' not in open('/proc/version').read().lower():
    print("âš ï¸  è­¦å‘Š: ä¼¼ä¹ä¸åœ¨ WSL2 ç¯å¢ƒä¸­")

try:
    subprocess.run([sys.executable, "app.py"], check=True)
except KeyboardInterrupt:
    print("\nğŸ‘‹ æœåŠ¡å·²åœæ­¢")
except Exception as e:
    print(f"\nâŒ å¯åŠ¨å¤±è´¥: {e}")
    print("\nğŸ’¡ å¦‚æœæ˜¯ CUDA é”™è¯¯ï¼Œå°è¯•:")
    print("   export CUDA_VISIBLE_DEVICES=''")
    print("   python app.py")
EOF

chmod +x start_wsl2.py
```

### æ–‡ä»¶ç³»ç»Ÿä¼˜åŒ–
```bash
# WSL2 ä¸­æ¨èåœ¨ Linux æ–‡ä»¶ç³»ç»Ÿä¸­æ“ä½œï¼Œæ€§èƒ½æ›´å¥½
cd /home/$USER/Auto-Subtitle-on-Generative-AI

# é¿å…åœ¨ Windows æ–‡ä»¶ç³»ç»Ÿ (/mnt/c/) ä¸­è¿è¡Œï¼Œæ€§èƒ½è¾ƒå·®
```

## â“ WSL2 GPU æ”¯æŒ FAQ

### Q0: WSL2 éœ€è¦å®‰è£… CUDA Toolkit å—ï¼Ÿ â­ æœ€é‡è¦
**A: ä¸éœ€è¦ï¼è¿™æ˜¯ WSL2 çš„æ ¸å¿ƒä¼˜åŠ¿ã€‚**

âœ… **åªéœ€è¦:**
- Windows ç«¯æœ€æ–° NVIDIA é©±åŠ¨ (>= 470.76)
- WSL2 æ­£ç¡®å®‰è£…

âŒ **ä¸éœ€è¦:**
- åœ¨ WSL2 ä¸­å®‰è£… CUDA Toolkit
- é…ç½® CUDA ç¯å¢ƒå˜é‡
- å®‰è£… cuDNN

ï¿½ **åŸç†**: Windows NVIDIA é©±åŠ¨è‡ªåŠ¨å‘ WSL2 æä¾› CUDA åº“æ–‡ä»¶åˆ° `/usr/lib/wsl/lib/` ç›®å½•ã€‚

### Q1: å¦‚ä½•ç¡®è®¤ WSL2 GPU æ”¯æŒæ­£å¸¸ï¼Ÿ
```bash
# æ£€æŸ¥ WSL GPU åº“
ls -la /usr/lib/wsl/lib/ | grep cuda

# æµ‹è¯• PyTorch GPU
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"
```

### Q2: CUDA é”™è¯¯ "no kernel image is available"
```bash
# è§£å†³æ–¹æ¡ˆ1: å¼ºåˆ¶ä½¿ç”¨ CPU
export CUDA_VISIBLE_DEVICES=''
python app.py

# è§£å†³æ–¹æ¡ˆ2: é‡æ–°å®‰è£…å…¼å®¹çš„ PyTorch
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
```

### Q2: å†…å­˜ä¸è¶³é”™è¯¯
```bash
# å¢åŠ  WSL2 å†…å­˜é™åˆ¶ï¼Œç¼–è¾‘ Windows ç«¯ .wslconfig
# [wsl2]
# memory=12GB

# é‡å¯ WSL2
wsl --shutdown
```

### Q3: ç«¯å£è®¿é—®é—®é¢˜
```bash
# Windows é˜²ç«å¢™å¯èƒ½é˜»æ­¢è®¿é—®ï¼Œæ·»åŠ é˜²ç«å¢™è§„åˆ™
# æˆ–è€…ä½¿ç”¨ localhost è€Œä¸æ˜¯ 127.0.0.1
```

### Q4: æ€§èƒ½ä¼˜åŒ–
```bash
# 1. ç¡®ä¿é¡¹ç›®åœ¨ Linux æ–‡ä»¶ç³»ç»Ÿä¸­ (/home/user/)
# 2. ä½¿ç”¨ conda ç¯å¢ƒç®¡ç†
# 3. å¯ç”¨ Windows Terminal æ€§èƒ½æ¨¡å¼
# 4. å…³é—­ä¸å¿…è¦çš„ Windows æœåŠ¡
```

### Q5: æ¨¡å‹ä¸‹è½½æ…¢
```bash
# é…ç½® HuggingFace é•œåƒ (ä¸­å›½ç”¨æˆ·)
export HF_ENDPOINT=https://hf-mirror.com
pip install -U huggingface_hub
```

## ğŸ“ WSL2 éƒ¨ç½²æ¸…å•

- [ ] Windows 11/10 å·²æ›´æ–°åˆ°æœ€æ–°ç‰ˆæœ¬
- [ ] WSL2 å·²å®‰è£…å¹¶é…ç½®
- [ ] Ubuntu 22.04 åœ¨ WSL2 ä¸­è¿è¡Œ
- [ ] `.wslconfig` å·²é…ç½®è¶³å¤Ÿå†…å­˜
- [ ] ç³»ç»Ÿä¾èµ–å·²å®‰è£… (ffmpeg, python3, git)
- [ ] Conda ç¯å¢ƒå·²åˆ›å»º
- [ ] PyTorch å·²å®‰è£… (CUDA æˆ– CPU ç‰ˆæœ¬)
- [ ] åº”ç”¨ä¾èµ–å·²å®‰è£…
- [ ] ç«¯å£ 5001 å¯è®¿é—®
- [ ] GPU æ”¯æŒå·²éªŒè¯ (å¯é€‰)

## ğŸ¯ æ€§èƒ½å»ºè®®

### æœ€ä½³é…ç½®
- **å†…å­˜**: 12GB+ åˆ†é…ç»™ WSL2
- **å­˜å‚¨**: é¡¹ç›®æ”¾åœ¨ Linux æ–‡ä»¶ç³»ç»Ÿ (`/home/user/`)
- **ç½‘ç»œ**: ä½¿ç”¨ `localhost` è®¿é—®æœåŠ¡
- **GPU**: å¦‚é‡é—®é¢˜ä¼˜å…ˆä½¿ç”¨ CPU æ¨¡å¼

### æ¨èå·¥ä½œæµ
1. å¼€å‘è°ƒè¯•: CPU æ¨¡å¼ï¼Œç¨³å®šå¿«é€Ÿ
2. ç”Ÿäº§ä½¿ç”¨: GPU æ¨¡å¼ï¼Œæ€§èƒ½æœ€ä½³  
3. æ‰¹é‡å¤„ç†: å¤§å†…å­˜é…ç½® + GPU åŠ é€Ÿ

---

ğŸ‰ **WSL2 éƒ¨ç½²å®Œæˆï¼äº«å—åœ¨ Windows ä¸Šçš„ Linux AI ä½“éªŒï¼**