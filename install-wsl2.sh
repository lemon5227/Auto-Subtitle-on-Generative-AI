#!/bin/bash
# =============================================================================
# Auto Subtitle Generator - WSL2 ä¸“ç”¨ä¸€é”®å®‰è£…è„šæœ¬  
# ğŸš€ é’ˆå¯¹ Windows WSL2 ç¯å¢ƒä¼˜åŒ–çš„ä¸æ»‘éƒ¨ç½²
# =============================================================================

set -e  # é‡åˆ°é”™è¯¯æ—¶é€€å‡º

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
NC='\033[0m' # No Color

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

log_wsl2() {
    echo -e "${PURPLE}[WSL2]${NC} $1"
}

# WSL2 ç¯å¢ƒæ£€æµ‹
check_wsl2_environment() {
    log_info "æ£€æµ‹ WSL2 ç¯å¢ƒ..."
    
    # æ£€æŸ¥æ˜¯å¦åœ¨ WSL2 ä¸­
    if [[ ! -f /proc/version ]] || ! grep -qi microsoft /proc/version; then
        log_error "ä¸åœ¨ WSL ç¯å¢ƒä¸­è¿è¡Œ"
        exit 1
    fi
    
    if grep -qi "WSL2" /proc/version || [[ -d "/sys/fs/cgroup/unified" ]]; then
        log_success "ç¡®è®¤è¿è¡Œåœ¨ WSL2 ç¯å¢ƒä¸­"
        WSL_VERSION=2
    else
        log_warning "å¯èƒ½åœ¨ WSL1 ç¯å¢ƒä¸­ï¼Œå»ºè®®å‡çº§åˆ° WSL2"
        WSL_VERSION=1
    fi
    
    # æ˜¾ç¤ºå‘è¡Œç‰ˆä¿¡æ¯
    if [[ -f /etc/os-release ]]; then
        . /etc/os-release
        log_info "Linux å‘è¡Œç‰ˆ: $PRETTY_NAME"
        
        # æ£€æŸ¥æ¨èçš„å‘è¡Œç‰ˆ
        case $ID in
            ubuntu)
                if [[ "$VERSION_ID" < "20.04" ]]; then
                    log_warning "å»ºè®®ä½¿ç”¨ Ubuntu 20.04 æˆ–æ›´æ–°ç‰ˆæœ¬"
                fi
                ;;
            debian)
                if [[ "$VERSION_ID" < "11" ]]; then
                    log_warning "å»ºè®®ä½¿ç”¨ Debian 11 æˆ–æ›´æ–°ç‰ˆæœ¬"
                fi
                ;;
        esac
    fi
}

# æ£€æŸ¥ Windows ç«¯ NVIDIA æ”¯æŒ
check_windows_nvidia() {
    log_wsl2 "æ£€æŸ¥ Windows ç«¯ NVIDIA GPU æ”¯æŒ..."
    
    # æ£€æŸ¥ WSL GPU åº“æ–‡ä»¶
    if [[ -d "/usr/lib/wsl/lib" ]]; then
        log_info "WSL GPU åº“ç›®å½•å­˜åœ¨: /usr/lib/wsl/lib"
        
        if ls /usr/lib/wsl/lib/libcuda.so* >/dev/null 2>&1; then
            log_success "âœ… æ£€æµ‹åˆ° WSL CUDA åº“æ–‡ä»¶"
            WSL_GPU_SUPPORT=true
            
            # æ˜¾ç¤º CUDA åº“ä¿¡æ¯
            log_info "å¯ç”¨çš„ GPU åº“æ–‡ä»¶:"
            ls -la /usr/lib/wsl/lib/ | grep -E "(cuda|nv|cudnn)" | head -5
            
            # æ£€æŸ¥é©±åŠ¨ç‰ˆæœ¬ä¿¡æ¯
            if [[ -f "/usr/lib/wsl/lib/libcuda.so.1" ]]; then
                log_info "CUDA è¿è¡Œæ—¶åº“: âœ… å¯ç”¨"
            fi
            
            log_success "ğŸ® GPU åŠ é€Ÿ: å·²å¯ç”¨ (é€šè¿‡ Windows NVIDIA é©±åŠ¨)"
            log_info "ğŸ’¡ è¯´æ˜: WSL2 é€šè¿‡ Windows é©±åŠ¨æä¾› CUDA æ”¯æŒï¼Œæ— éœ€å•ç‹¬å®‰è£…"
        else
            log_warning "âŒ WSL GPU åº“æ–‡ä»¶ä¸å®Œæ•´"
            WSL_GPU_SUPPORT=false
        fi
    else
        log_warning "âŒ WSL GPU åº“ç›®å½•ä¸å­˜åœ¨"
        WSL_GPU_SUPPORT=false
    fi
    
    if [[ "$WSL_GPU_SUPPORT" == "false" ]]; then
        log_info "ğŸ”§ GPU æ”¯æŒæ£€æŸ¥å¤±è´¥ï¼Œå¯èƒ½åŸå› :"
        log_info "   1. Windows NVIDIA é©±åŠ¨ç‰ˆæœ¬è¿‡ä½ (éœ€è¦ >= 470.76)"
        log_info "   2. æ²¡æœ‰å®‰è£… NVIDIA GPU é©±åŠ¨"
        log_info "   3. WSL2 é…ç½®é—®é¢˜"
        log_info "ğŸ’» å°†ä½¿ç”¨ CPU æ¨¡å¼ï¼Œä»å¯æ­£å¸¸è¿è¡Œ"
    fi
}

# WSL2 ç³»ç»Ÿä¼˜åŒ–
optimize_wsl2_system() {
    log_wsl2 "åº”ç”¨ WSL2 ç³»ç»Ÿä¼˜åŒ–..."
    
    # è®¾ç½®ç¯å¢ƒå˜é‡ä¼˜åŒ–
    cat >> ~/.bashrc << 'EOF'

# WSL2 AI ä¼˜åŒ–ç¯å¢ƒå˜é‡
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128
export CUDA_LAUNCH_BLOCKING=1
export OMP_NUM_THREADS=4
export TOKENIZERS_PARALLELISM=false

# HuggingFace å›½å†…é•œåƒ (å¯é€‰)
# export HF_ENDPOINT=https://hf-mirror.com
EOF

    log_success "WSL2 ç¯å¢ƒå˜é‡å·²é…ç½®"
}

# æ£€æŸ¥å’Œå®‰è£…ç³»ç»Ÿä¾èµ–
install_system_deps() {
    log_info "æ›´æ–°åŒ…ç®¡ç†å™¨..."
    sudo apt update
    
    log_info "å®‰è£…ç³»ç»Ÿä¾èµ–..."
    sudo apt install -y \
        python3 python3-pip python3-venv python3-dev \
        git curl wget unzip \
        ffmpeg \
        build-essential \
        software-properties-common \
        ca-certificates \
        apt-transport-https
    
    log_success "ç³»ç»Ÿä¾èµ–å®‰è£…å®Œæˆ"
}

# å®‰è£… Conda (é’ˆå¯¹ WSL2 ä¼˜åŒ–)
install_conda() {
    if command -v conda &> /dev/null; then
        log_success "Conda å·²å®‰è£…"
        return 0
    fi
    
    log_info "å®‰è£… Miniconda (WSL2 ä¼˜åŒ–ç‰ˆ)..."
    
    # ä¸‹è½½ Miniconda
    CONDA_URL="https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh"
    wget -q "$CONDA_URL" -O miniconda.sh
    
    # é™é»˜å®‰è£…
    bash miniconda.sh -b -p "$HOME/miniconda"
    
    # æ·»åŠ åˆ° PATH
    echo 'export PATH="$HOME/miniconda/bin:$PATH"' >> ~/.bashrc
    export PATH="$HOME/miniconda/bin:$PATH"
    
    # åˆå§‹åŒ– conda
    "$HOME/miniconda/bin/conda" init bash
    
    # æ¸…ç†
    rm miniconda.sh
    
    log_success "Miniconda å®‰è£…å®Œæˆ"
}

# åˆ›å»º Python ç¯å¢ƒ
setup_python_env() {
    log_info "åˆ›å»º Python ç¯å¢ƒ..."
    
    # ç¡®ä¿ conda å¯ç”¨
    export PATH="$HOME/miniconda/bin:$PATH"
    
    # åˆ›å»ºç¯å¢ƒ
    conda create -n whisper-app python=3.11 -y
    
    log_success "Python ç¯å¢ƒåˆ›å»ºå®Œæˆ"
}

# å…‹éš†æˆ–æ›´æ–°é¡¹ç›®
setup_project() {
    log_info "è®¾ç½®é¡¹ç›®ä»£ç ..."
    
    PROJECT_DIR="$HOME/Auto-Subtitle-on-Generative-AI"
    
    if [[ -d "$PROJECT_DIR" ]]; then
        log_info "é¡¹ç›®ç›®å½•å·²å­˜åœ¨ï¼Œæ›´æ–°ä»£ç ..."
        cd "$PROJECT_DIR"
        git pull origin main || log_warning "ä»£ç æ›´æ–°å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°ç‰ˆæœ¬"
    else
        log_info "å…‹éš†é¡¹ç›®ä»“åº“..."
        git clone https://github.com/lemon5227/Auto-Subtitle-on-Generative-AI.git "$PROJECT_DIR"
        cd "$PROJECT_DIR"
    fi
    
    log_success "é¡¹ç›®ä»£ç å·²å‡†å¤‡å®Œæˆ"
}

# å®‰è£… Python ä¾èµ– (WSL2 ç‰¹åŒ–)
install_python_deps() {
    log_info "æ¿€æ´» Python ç¯å¢ƒå¹¶å®‰è£…ä¾èµ–..."
    
    # æ¿€æ´»ç¯å¢ƒ
    source "$HOME/miniconda/bin/activate" whisper-app
    
    # å‡çº§åŸºç¡€å·¥å…·
    pip install --upgrade pip setuptools wheel
    
    # WSL2 æ™ºèƒ½ PyTorch å®‰è£…
    log_info "å®‰è£… PyTorch (WSL2 ä¸“ç”¨é…ç½®)..."
    
    if [[ "$WSL_GPU_SUPPORT" == "true" ]]; then
        log_success "ğŸ® å®‰è£… GPU åŠ é€Ÿç‰ˆ PyTorch..."
        log_info "   ä½¿ç”¨ Windows NVIDIA é©±åŠ¨æä¾›çš„ CUDA æ”¯æŒ"
        pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
        
        # éªŒè¯ GPU æ”¯æŒ
        log_info "éªŒè¯ GPU æ”¯æŒ..."
        python -c "
import torch
import os
print(f'PyTorch: {torch.__version__}')
print(f'CUDA available: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'GPU: {torch.cuda.get_device_name(0)}')
    print('âœ… WSL2 GPU åŠ é€Ÿé…ç½®æˆåŠŸ')
else:
    print('âš ï¸  GPU ä¸å¯ç”¨ï¼Œä½†è¿™æ˜¯æ­£å¸¸çš„ï¼Œä¼šåœ¨è¿è¡Œæ—¶æ£€æµ‹')
"
    else
        log_info "ğŸ’» å®‰è£… CPU ç‰ˆæœ¬ PyTorch..."
        log_info "   æ³¨æ„: å³ä½¿å®‰è£… CPU ç‰ˆæœ¬ï¼Œå¦‚æœåç»­æ£€æµ‹åˆ° GPU ä¹Ÿå¯ä»¥ä½¿ç”¨"
        pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
    fi
    
    # å®‰è£…åº”ç”¨ä¾èµ–
    log_info "å®‰è£…åº”ç”¨ä¾èµ–åŒ…..."
    pip install -r requirements.txt
    
    log_success "Python ä¾èµ–å®‰è£…å®Œæˆ"
}

# åˆ›å»º WSL2 ä¸“ç”¨å¯åŠ¨å™¨
create_wsl2_launcher() {
    log_info "åˆ›å»º WSL2 ä¸“ç”¨å¯åŠ¨å™¨..."
    
    cat > start_wsl2.py << 'EOF'
#!/usr/bin/env python3
"""
WSL2 ä¸“ç”¨å¯åŠ¨è„šæœ¬ - AI å­—å¹•ç”Ÿæˆå™¨
ğŸš€ é’ˆå¯¹ WSL2 ç¯å¢ƒä¼˜åŒ–ï¼Œè§£å†³å¸¸è§å…¼å®¹æ€§é—®é¢˜
"""
import os
import sys
import subprocess
import platform

def print_wsl2_info():
    print("=" * 60)
    print("ğŸ”§ WSL2 ä¼˜åŒ–å¯åŠ¨å™¨ - AI å­—å¹•ç”Ÿæˆå™¨")
    print("ğŸš€ é’ˆå¯¹ Windows WSL2 ç¯å¢ƒä¼˜åŒ–")
    print("=" * 60)
    
    # æ˜¾ç¤ºç¯å¢ƒä¿¡æ¯
    print(f"ğŸ§ Linux å‘è¡Œç‰ˆ: {platform.platform()}")
    print(f"ğŸ Python ç‰ˆæœ¬: {sys.version.split()[0]}")
    
    # WSL2 ä¼˜åŒ–è®¾ç½®
    optimizations = {
        'PYTORCH_CUDA_ALLOC_CONF': 'max_split_size_mb:128',
        'CUDA_LAUNCH_BLOCKING': '1',
        'OMP_NUM_THREADS': '4',
        'TOKENIZERS_PARALLELISM': 'false'
    }
    
    print("\nğŸ”§ WSL2 ä¼˜åŒ–é…ç½®:")
    for key, value in optimizations.items():
        os.environ[key] = value
        print(f"   {key}={value}")

def check_gpu_support():
    """æ£€æŸ¥ WSL2 GPU æ”¯æŒ"""
    print("\nğŸ” WSL2 GPU ç¯å¢ƒæ£€æŸ¥:")
    
    # æ£€æŸ¥ WSL GPU åº“
    import os
    wsl_cuda_lib = "/usr/lib/wsl/lib/libcuda.so.1"
    wsl_lib_exists = os.path.exists(wsl_cuda_lib)
    print(f"   WSL CUDA åº“: {'âœ… å­˜åœ¨' if wsl_lib_exists else 'âŒ ä¸å­˜åœ¨'}")
    
    if wsl_lib_exists:
        print("   ğŸ’¡ é€šè¿‡ Windows NVIDIA é©±åŠ¨æä¾› GPU æ”¯æŒ")
    else:
        print("   ğŸ’¡ éœ€è¦åœ¨ Windows ç«¯å®‰è£…/æ›´æ–° NVIDIA é©±åŠ¨ (>= 470.76)")
    
    try:
        import torch
        cuda_available = torch.cuda.is_available()
        print(f"   PyTorch CUDA: {'âœ… å¯ç”¨' if cuda_available else 'âŒ ä¸å¯ç”¨'}")
        
        if cuda_available:
            print(f"   GPU è®¾å¤‡: {torch.cuda.get_device_name(0)}")
            print(f"   CUDA ç‰ˆæœ¬: {torch.version.cuda}")
            print("   ğŸš€ WSL2 GPU åŠ é€Ÿå·²å¯ç”¨")
        else:
            print("   ğŸ’» å°†ä½¿ç”¨ CPU æ¨¡å¼ (ä»å¯æ­£å¸¸è¿è¡Œ)")
        
        return cuda_available
    except Exception as e:
        print(f"   âš ï¸  PyTorch æ£€æŸ¥å¤±è´¥: {e}")
        return False

def start_app():
    """å¯åŠ¨åº”ç”¨"""
    print("\nğŸŒ è®¿é—®åœ°å€:")
    print("   ğŸ“º å®æ—¶è½¬å½•: http://localhost:5001/realtime.html")
    print("   ğŸ¬ æ–‡ä»¶å¤„ç†: http://localhost:5001/app.html")
    print("\nğŸ”” æç¤º:")
    print("   - åœ¨ Windows æµè§ˆå™¨ä¸­æ‰“å¼€ä¸Šè¿°åœ°å€")
    print("   - æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
    print("   - å¦‚é‡ CUDA é”™è¯¯ï¼ŒæœåŠ¡ä¼šè‡ªåŠ¨å›é€€åˆ° CPU æ¨¡å¼")
    print("\n" + "-" * 60)
    
    try:
        subprocess.run([sys.executable, "app.py"], check=True)
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æœåŠ¡å·²åœæ­¢ï¼Œè°¢è°¢ä½¿ç”¨!")
    except FileNotFoundError:
        print("\nâŒ app.py æ–‡ä»¶æœªæ‰¾åˆ°")
        print("ğŸ“ è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬")
    except Exception as e:
        print(f"\nâŒ å¯åŠ¨å¤±è´¥: {e}")
        print("\nğŸ’¡ æ•…éšœæ’é™¤å»ºè®®:")
        print("   1. æ£€æŸ¥ç«¯å£ 5001 æ˜¯å¦è¢«å ç”¨")
        print("   2. å°è¯•é‡æ–°æ¿€æ´» conda ç¯å¢ƒ")
        print("   3. å¦‚æœæ˜¯ GPU é”™è¯¯ï¼Œå¯ä»¥å¼ºåˆ¶ä½¿ç”¨ CPU:")
        print("      export CUDA_VISIBLE_DEVICES=''")
        print("      python app.py")

if __name__ == "__main__":
    print_wsl2_info()
    check_gpu_support()
    start_app()
EOF

    chmod +x start_wsl2.py
    log_success "WSL2 å¯åŠ¨å™¨å·²åˆ›å»º: start_wsl2.py"
}

# éªŒè¯å®‰è£…
verify_installation() {
    log_info "éªŒè¯å®‰è£…..."
    
    # æ¿€æ´»ç¯å¢ƒè¿›è¡ŒéªŒè¯
    source "$HOME/miniconda/bin/activate" whisper-app
    
    # æ£€æŸ¥å…³é”®ç»„ä»¶
    python -c "
import sys
try:
    import torch, flask, whisper
    print('âœ… æ ¸å¿ƒä¾èµ–æ£€æŸ¥é€šè¿‡')
    print(f'PyTorch: {torch.__version__}')
    print(f'CUDA å¯ç”¨: {torch.cuda.is_available()}')
except ImportError as e:
    print(f'âŒ ä¾èµ–æ£€æŸ¥å¤±è´¥: {e}')
    sys.exit(1)
" || {
        log_error "Python ä¾èµ–éªŒè¯å¤±è´¥"
        return 1
    }
    
    # æ£€æŸ¥ ffmpeg
    if ! command -v ffmpeg &> /dev/null; then
        log_error "ffmpeg æœªæ­£ç¡®å®‰è£…"
        return 1
    fi
    
    log_success "å®‰è£…éªŒè¯é€šè¿‡"
}

# æ˜¾ç¤ºå®Œæˆä¿¡æ¯
show_completion_info() {
    echo ""
    echo "ğŸ‰" "=" * 50
    echo "ğŸŠ WSL2 ç¯å¢ƒ AI å­—å¹•ç”Ÿæˆå™¨å®‰è£…å®Œæˆ!"
    echo "=" * 55
    echo ""
    echo "ğŸ“‹ å¿«é€Ÿå¯åŠ¨æŒ‡å—:"
    echo "   1ï¸âƒ£ æ¿€æ´»ç¯å¢ƒ: conda activate whisper-app"
    echo "   2ï¸âƒ£ è¿›å…¥ç›®å½•: cd ~/Auto-Subtitle-on-Generative-AI"
    echo "   3ï¸âƒ£ å¯åŠ¨æœåŠ¡: python start_wsl2.py"
    echo ""
    echo "ğŸŒ æˆ–è€…ç›´æ¥è¿è¡Œ WSL2 ä¼˜åŒ–å¯åŠ¨å™¨:"
    echo "   cd ~/Auto-Subtitle-on-Generative-AI && conda activate whisper-app && python start_wsl2.py"
    echo ""
    echo "ğŸ”— è®¿é—®åœ°å€ (åœ¨ Windows æµè§ˆå™¨ä¸­):"
    echo "   ğŸ“º å®æ—¶è½¬å½•: http://localhost:5001/realtime.html"
    echo "   ğŸ¬ æ–‡ä»¶å¤„ç†: http://localhost:5001/app.html"
    echo ""
    echo "ğŸ’¡ å°æç¤º:"
    echo "   - WSL2 ç¯å¢ƒå·²ä¼˜åŒ–ï¼Œæ”¯æŒ GPU åŠ é€Ÿ (å¦‚æœå¯ç”¨)"
    echo "   - é¡¹ç›®ä½äº: ~/Auto-Subtitle-on-Generative-AI"
    echo "   - é‡åˆ°é—®é¢˜æŸ¥çœ‹: README.wsl2.md"
    echo ""
    echo "ğŸ¯ æ€§èƒ½å»ºè®®:"
    echo "   - ç¡®ä¿ Windows åˆ†é…è¶³å¤Ÿå†…å­˜ç»™ WSL2 (å»ºè®® 8GB+)"
    echo "   - ä½¿ç”¨ localhost è€Œä¸æ˜¯ 127.0.0.1 è®¿é—®æœåŠ¡"
    echo ""
}

# ä¸»å‡½æ•°
main() {
    echo "======================================================"
    echo "ğŸš€ Auto Subtitle Generator - WSL2 ä¸€é”®éƒ¨ç½²è„šæœ¬"
    echo "ğŸ”§ ä¸“ä¸º Windows WSL2 ç¯å¢ƒä¼˜åŒ–"
    echo "======================================================"
    
    # æ£€æŸ¥ WSL2 ç¯å¢ƒ
    check_wsl2_environment
    
    # æ£€æŸ¥ GPU æ”¯æŒ
    check_windows_nvidia
    
    # ç³»ç»Ÿä¼˜åŒ–
    optimize_wsl2_system
    
    # å®‰è£…ç³»ç»Ÿä¾èµ–
    install_system_deps
    
    # å®‰è£… Conda
    install_conda
    
    # è®¾ç½®é¡¹ç›®
    setup_project
    
    # åˆ›å»º Python ç¯å¢ƒ
    setup_python_env
    
    # å®‰è£… Python ä¾èµ–
    install_python_deps
    
    # åˆ›å»ºå¯åŠ¨å™¨
    create_wsl2_launcher
    
    # éªŒè¯å®‰è£…
    if verify_installation; then
        show_completion_info
    else
        log_error "å®‰è£…éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯"
        exit 1
    fi
    
    # è¯¢é—®æ˜¯å¦ç«‹å³å¯åŠ¨
    echo ""
    read -p "æ˜¯å¦ç°åœ¨å¯åŠ¨åº”ç”¨? (y/N): " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        echo ""
        log_info "å¯åŠ¨ AI å­—å¹•ç”Ÿæˆå™¨..."
        cd ~/Auto-Subtitle-on-Generative-AI
        source "$HOME/miniconda/bin/activate" whisper-app
        python start_wsl2.py
    else
        echo ""
        log_success "å®‰è£…å®Œæˆ! ä½¿ç”¨ä¸Šè¿°å‘½ä»¤æ‰‹åŠ¨å¯åŠ¨æœåŠ¡"
    fi
}

# é”™è¯¯å¤„ç†
trap 'log_error "å®‰è£…è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ (${BASH_SOURCE}:${LINENO})ï¼Œè¯·æ£€æŸ¥ä¸Šæ–¹æ—¥å¿—"; exit 1' ERR

# è¿è¡Œä¸»å‡½æ•°
main "$@"