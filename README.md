# Auto-Subtitle-on-Generative-AI

<div align="center">

## ğŸŒ Choose Your Language | é€‰æ‹©è¯­è¨€

| ğŸ‡¨ğŸ‡³ ä¸­æ–‡ | ğŸ‡ºğŸ‡¸ English | ğŸ macOS | ğŸ§ Linux | ğŸªŸ WSL2 | ğŸ® AMD |
|:---:|:---:|:---:|:---:|:---:|:---:|
| [ğŸ“– ä¸­æ–‡æ–‡æ¡£](README.zh-CN.md) | [ğŸ“– English](README.en.md) | [ğŸ macOS æŒ‡å—](README.macOS.md) | [ğŸ§ Linux æŒ‡å—](README.linux.md) | [ğŸ”§ WSL2 æŒ‡å—](README.wsl2.md) | [ğŸ® AMD ç¬”è®°æœ¬](README.amd.md) |
| å®Œæ•´ä¸­æ–‡è¯´æ˜ | Full English Guide | Apple Silicon ä¼˜åŒ– | ä¸æ»‘ä¸€é”®éƒ¨ç½² | Windows ç”¨æˆ·æ¨è | AMD GPU ä¸“ç”¨ |

---

</div>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.8%2B-blue.svg" alt="Python Version">
  <img src="https://img.shields.io/badge/PyTorch-2.0%2B-orange.svg" alt="PyTorch">
  <img src="https://img.shields.io/badge/Platform-Windows%20%7C%20macOS%20%7C%20Linux-lightgrey.svg" alt="Platform">
  <img src="https://img.shields.io/badge/License-MIT-green.svg" alt="License">
</p>

<p align="center">
  <strong>ğŸ¤ æ™ºèƒ½è¯­éŸ³å­—å¹•ç”Ÿæˆå™¨</strong><br>
  åŸºäº Whisper Large-v3 Turbo çš„å®æ—¶è½¬å½•å’Œå­—å¹•ç”Ÿæˆç³»ç»Ÿ
</p></p>

## âœ¨ ä¸»è¦åŠŸèƒ½

- ğŸš€ **å®æ—¶è¯­éŸ³è½¬å½•** - æ”¯æŒéº¦å…‹é£å®æ—¶ç›‘å¬å’Œè½¬å½•
- ğŸ¯ **å¤šæ¨¡å‹æ”¯æŒ** - Whisper Large-v3 Turbo, SenseVoice, Distil-Whisper
- ğŸ¤– **Qwen3æ™ºèƒ½æ ¡å¯¹** - é›†æˆæœ€æ–°Qwen3å¤§æ¨¡å‹ï¼Œä¸“ä¸šASRçº é”™ä¸ç¿»è¯‘
- ğŸŒ **å¤šè¯­è¨€è¯†åˆ«** - ä¸­æ–‡ã€è‹±æ–‡ã€æ—¥è¯­ã€éŸ©è¯­ç­‰
- ğŸ’» **è·¨å¹³å°æ”¯æŒ** - Windows, macOS (å« Apple Silicon), Linux
- ğŸ® **æ™ºèƒ½GPUæ£€æµ‹** - è‡ªåŠ¨æ£€æµ‹å¹¶é€‚é… NVIDIA CUDA / AMD ROCm / Apple MPS
- âš¡ **é€šç”¨ç¡¬ä»¶åŠ é€Ÿ** - æœ‰GPUç”¨GPUï¼Œæ— GPUæ™ºèƒ½å›é€€CPUæ¨¡å¼
- ğŸ“¹ **è§†é¢‘å¤„ç†** - æœ¬åœ°æ–‡ä»¶å’Œ YouTube è§†é¢‘ä¸‹è½½è½¬å½•
- ğŸ”„ **å­—å¹•ç¿»è¯‘** - åŸºäº Helsinki-NLP å’Œ Qwen3 çš„å¤šè¯­è¨€ç¿»è¯‘
- ğŸ’¾ **å¤šæ ¼å¼å¯¼å‡º** - VTT, SRT, çº¯æ–‡æœ¬æ ¼å¼
- ğŸ¨ **ç°ä»£åŒ–ç•Œé¢** - åŸºäº Tailwind CSS çš„å“åº”å¼è®¾è®¡

> ğŸ†• **æœ€æ–°æ›´æ–°**: Qwen3ç³»åˆ—æ¨¡å‹ - æ›´å¼ºçš„ASRçº é”™ã€ä¸“ä¸šå­—å¹•ç¿»è¯‘ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç†è§£ï¼[æŸ¥çœ‹è¯¦æƒ…](README.qwen3.md)

## ğŸ–¥ï¸ æ”¯æŒçš„å¹³å°å’ŒåŠ é€Ÿ

| å¹³å° | CPU | NVIDIA GPU | AMD GPU | Apple GPU | æ¨èé…ç½® |
|------|-----|------------|---------|-----------|----------|
| **Windows** | âœ… | CUDA âœ… | ROCm âš ï¸ | âŒ | RTX 3060+ |
| **macOS (Apple Silicon)** | âœ… | âŒ | âŒ | MPS âœ… | M1/M2/M3 16GB+ |
| **macOS (Intel)** | âœ… | âŒ | âŒ | âŒ | 8GB+ RAM |
| **Linux** | âœ… | CUDA âœ… | ROCm âœ… | âŒ | RTX 3060+ / RX 6600+ |
| **AMD ç¬”è®°æœ¬** | âœ… | âŒ | ROCm âœ… | âŒ | RX 6600 XT / Ryzen 7 |

> ğŸ® **æ™ºèƒ½GPUæ£€æµ‹**: ç³»ç»Ÿè‡ªåŠ¨æ£€æµ‹å¯ç”¨ç¡¬ä»¶ï¼Œä¼˜å…ˆä½¿ç”¨GPUåŠ é€Ÿï¼Œæ— GPUæ—¶æ™ºèƒ½å›é€€CPUæ¨¡å¼
> ğŸ”´ **AMD GPU**: æ”¯æŒ RX 6000/7000/5000 ç³»åˆ—ï¼ŒROCm å¹³å°åŠ é€Ÿï¼Œç¬”è®°æœ¬ç”¨æˆ·æ¨è

## ğŸ® æ™ºèƒ½GPUæ£€æµ‹ç³»ç»Ÿ

æœ¬é¡¹ç›®é‡‡ç”¨å…ˆè¿›çš„æ™ºèƒ½GPUæ£€æµ‹å’Œé€‚é…ç³»ç»Ÿï¼Œè‡ªåŠ¨è¯†åˆ«å¹¶ä¼˜åŒ–å„ç§ç¡¬ä»¶ç¯å¢ƒï¼š

### ğŸ” è‡ªåŠ¨ç¡¬ä»¶æ£€æµ‹
- **NVIDIA GPU**: æ£€æµ‹CUDAé©±åŠ¨ï¼Œè‡ªåŠ¨å¯ç”¨CUDAåŠ é€Ÿ
- **AMD GPU**: æ£€æµ‹ROCmå¹³å°ï¼Œæ”¯æŒRX 6000/7000/5000ç³»åˆ—
- **Apple Silicon**: æ£€æµ‹MPSæ”¯æŒï¼ŒApple Silicon Macä¼˜åŒ–
- **CPUæ¨¡å¼**: æ— GPUæ—¶è‡ªåŠ¨å›é€€ï¼Œä¼˜åŒ–å¤šçº¿ç¨‹æ€§èƒ½

### âš¡ æ™ºèƒ½è®¾å¤‡é€‰æ‹©
```bash
# ç³»ç»Ÿè‡ªåŠ¨é€‰æ‹©æœ€ä½³è®¾å¤‡
python start_smart.py  # æ™ºèƒ½å¯åŠ¨å™¨ä¼šæ˜¾ç¤ºæ£€æµ‹ç»“æœ

# ç¤ºä¾‹è¾“å‡º:
# ğŸ¯ é€‰æ‹©è®¾å¤‡: cuda
# ğŸ“Š è®¾å¤‡ä¿¡æ¯: ğŸŸ¢ NVIDIA GPU (RTX 3060, 6GB) - acceptable æ€§èƒ½
# ğŸ’¡ ä½¿ç”¨ CUDA åŠ é€Ÿè·å¾—æœ€ä½³æ€§èƒ½
```

### ğŸ¯ æ€§èƒ½ä¼˜åŒ–å»ºè®®
ç³»ç»Ÿä¼šæ ¹æ®æ£€æµ‹åˆ°çš„ç¡¬ä»¶æä¾›ä¸ªæ€§åŒ–å»ºè®®ï¼š
- **NVIDIAç”¨æˆ·**: æ˜¾å­˜å……è¶³æ—¶æ¨èlargeæ¨¡å‹
- **AMDç”¨æˆ·**: æ¨èsmall/baseæ¨¡å‹ï¼ŒROCmä¼˜åŒ–
- **Apple Silicon**: mediumæ¨¡å‹æ€§èƒ½æœ€ä½³
- **CPUç”¨æˆ·**: baseæ¨¡å‹è·å¾—æœ€ä½³é€Ÿåº¦

### ğŸ”§ ç¯å¢ƒéªŒè¯å·¥å…·
```bash
# å®Œæ•´ç¯å¢ƒæ£€æµ‹
python test_gpu_detection.py

# å¿«é€ŸGPUæ£€æµ‹
python gpu_detector.py
```

æœ¬ä»“åº“æä¾›å®Œæ•´çš„ demo å®ç°ï¼Œæ”¯æŒç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ï¼ˆéœ€è¦é¢å¤–çš„å®‰å…¨åŠ å›ºå’Œé”™è¯¯å¤„ç†ï¼‰ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ğŸ¯ ä¸€é”®å®‰è£…ï¼ˆæ¨è - é€‚ç”¨äºæ‰€æœ‰å¹³å°ï¼‰
```bash
# 1. å…‹éš†ä»“åº“
git clone https://github.com/lemon5227/Auto-Subtitle-on-Generative-AI.git
cd Auto-Subtitle-on-Generative-AI

# 2. ä½¿ç”¨æ™ºèƒ½å¯åŠ¨å™¨ï¼ˆè‡ªåŠ¨æ£€æŸ¥ä¾èµ–ã€é…ç½®ç¯å¢ƒï¼‰
python start.py
```

**æ™ºèƒ½å¯åŠ¨å™¨åŠŸèƒ½**ï¼š
- âœ… è‡ªåŠ¨æ£€æµ‹æ“ä½œç³»ç»Ÿå’ŒPythonç¯å¢ƒ
- âœ… æ™ºèƒ½å®‰è£…ç¼ºå¤±çš„ç³»ç»Ÿä¾èµ–ï¼ˆffmpegç­‰ï¼‰
- âœ… åˆ›å»ºç‹¬ç«‹çš„è™šæ‹Ÿç¯å¢ƒé¿å…å†²çª
- âœ… æ£€æµ‹GPUç¡¬ä»¶å¹¶é…ç½®æœ€ä¼˜åŠ é€Ÿ
- âœ… è‡ªåŠ¨ä¸‹è½½å¿…éœ€æ¨¡å‹æ–‡ä»¶
- âœ… ä¸€é”®å¯åŠ¨WebæœåŠ¡

### ğŸš€ å¹³å°ç‰¹å®šä¸æ»‘éƒ¨ç½²

#### ğŸ§ Linux è¶…çº§ä¸æ»‘ä¸€é”®å®‰è£…
```bash
# åªéœ€ä¸€æ¡å‘½ä»¤ï¼Œå…¨è‡ªåŠ¨éƒ¨ç½²ï¼
curl -fsSL https://raw.githubusercontent.com/lemon5227/Auto-Subtitle-on-Generative-AI/main/install-linux.sh | bash
```

#### ğŸªŸ Windows WSL2 ä¸“ç”¨éƒ¨ç½²
```bash
# WSL2 ç¯å¢ƒä¼˜åŒ–éƒ¨ç½²
curl -fsSL https://raw.githubusercontent.com/lemon5227/Auto-Subtitle-on-Generative-AI/main/install-wsl2.sh | bash
```

#### ğŸ® AMD ç¬”è®°æœ¬ä¸“ç”¨éƒ¨ç½²
```bash
# AMD GPU ç¬”è®°æœ¬ç”¨æˆ·ä¸“ç”¨ä¸€é”®éƒ¨ç½²
curl -fsSL https://raw.githubusercontent.com/lemon5227/Auto-Subtitle-on-Generative-AI/main/install-amd.sh | bash
```

| å¹³å° | éƒ¨ç½²æ–¹æ¡ˆ | ç‰¹è‰²ä¼˜åŒ– | å®‰è£…æ—¶é—´ |
|------|----------|----------|----------|
| ğŸ§ **Linux** | [ğŸš€ ä¸€é”®è„šæœ¬](README.linux.md) | æ£€æµ‹å‘è¡Œç‰ˆ â€¢ è‡ªåŠ¨è£…ä¾èµ– â€¢ GPUåŠ é€Ÿ | ~5åˆ†é’Ÿ |
| ğŸ® **AMD ç¬”è®°æœ¬** | [ğŸ”´ AMDä¸“ç”¨](README.amd.md) | ROCmæ”¯æŒ â€¢ AMD GPUä¼˜åŒ– â€¢ ç¬”è®°æœ¬é€‚é… | ~6åˆ†é’Ÿ |
| ğŸªŸ **WSL2** | [ğŸ”§ WSL2ä¸“ç”¨](README.wsl2.md) | GPUæ”¯æŒ â€¢ ç¯å¢ƒä¼˜åŒ– â€¢ å…¼å®¹æ€§ä¿®å¤ | ~6åˆ†é’Ÿ |
| ğŸ **macOS** | [ğŸ Appleä¼˜åŒ–](README.macOS.md) | Apple Silicon â€¢ MPSåŠ é€Ÿ â€¢ Homebrew | ~8åˆ†é’Ÿ |
| ğŸªŸ **Windows** | [å‚è€ƒé€šç”¨æ­¥éª¤](#ğŸš€-å¿«é€Ÿå¼€å§‹) | CUDAæ”¯æŒ â€¢ è™šæ‹Ÿç¯å¢ƒ | ~10åˆ†é’Ÿ |

> ğŸ’¡ **æœ€ä½³ä½“éªŒ**: 
> - **Linux** åŸç”Ÿç”¨æˆ·: ä½¿ç”¨ä¸€é”®è„šæœ¬ï¼Œæ€§èƒ½æœ€ä½³
> - **AMD ç¬”è®°æœ¬** ç”¨æˆ·: ä½¿ç”¨AMDä¸“ç”¨è„šæœ¬ï¼ŒROCm GPUåŠ é€Ÿ
> - **Windows** ç”¨æˆ·: æ¨è WSL2 æ–¹æ¡ˆï¼Œä½“éªŒæ¥è¿‘åŸç”Ÿ Linux
> - **macOS** ç”¨æˆ·: ä½¿ç”¨ä¸“ç”¨æŒ‡å—ï¼ŒApple Silicon ä¼˜åŒ–

## ğŸ“± åŠŸèƒ½æ¼”ç¤º

### å®æ—¶è½¬å½•ç•Œé¢
- **è®¿é—®åœ°å€**: http://127.0.0.1:5001/realtime.html
- **åŠŸèƒ½**: å®æ—¶è¯­éŸ³è¯†åˆ«ã€å¤šè¯­è¨€æ”¯æŒã€å­—å¹•å¯¼å‡º

### æ–‡ä»¶å¤„ç†ç•Œé¢  
- **è®¿é—®åœ°å€**: http://127.0.0.1:5001/app.html
- **åŠŸèƒ½**: è§†é¢‘ä¸Šä¼ ã€æ‰¹é‡è½¬å½•ã€ç¿»è¯‘ã€æ¨¡å‹ç®¡ç†

## ğŸ“‹ ç³»ç»Ÿä¾èµ–

### å¿…éœ€ç»„ä»¶
- **ffmpeg**: éŸ³é¢‘è§†é¢‘å¤„ç†æ ¸å¿ƒ
- **Python 3.8+**: æ¨è 3.11 ç‰ˆæœ¬
- **Git**: ä»£ç å…‹éš†å’Œç‰ˆæœ¬ç®¡ç†

### å¿«é€Ÿå®‰è£…ç³»ç»Ÿä¾èµ–

**Ubuntu/Debian Linux:**
```bash
sudo apt update && sudo apt install -y ffmpeg python3 python3-pip git
```

**CentOS/RHEL/Fedora Linux:**
```bash
# CentOS/RHEL
sudo yum install -y epel-release && sudo yum install -y ffmpeg python3 python3-pip git

# Fedora  
sudo dnf install -y ffmpeg python3 python3-pip git
```

**macOS:**
```bash
brew install ffmpeg python@3.11 git
```

**Windows:**
```bash
# ä½¿ç”¨ Chocolatey
choco install ffmpeg python git

# æˆ–ä¸‹è½½å®‰è£…åŒ…
# Python: https://python.org/downloads
# FFmpeg: https://ffmpeg.org/download.html
# Git: https://git-scm.com/downloads
```

### Python ä¾èµ–ï¼ˆè‡ªåŠ¨å®‰è£…ï¼‰
ä¸»è¦ç»„ä»¶ï¼ˆè¯¦è§ `requirements.txt`ï¼‰ï¼š
- **Flask**: Web æœåŠ¡æ¡†æ¶
- **openai-whisper**: è¯­éŸ³è¯†åˆ«æ ¸å¿ƒ
- **torch**: PyTorch æ·±åº¦å­¦ä¹ æ¡†æ¶  
- **transformers**: ç¿»è¯‘æ¨¡å‹æ”¯æŒ

## ğŸ macOS ç”¨æˆ·å¿«é€Ÿé…ç½®æŒ‡å—

### ç³»ç»Ÿè¦æ±‚
- macOS 10.15+ (æ¨è macOS 12+)
- Python 3.8+ (æ¨è Python 3.11)
- è‡³å°‘ 8GB RAM (æ¨è 16GB+)

### 1. å®‰è£… Homebrewï¼ˆå¦‚æœæ²¡æœ‰ï¼‰
```bash
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
```

### 2. å®‰è£…ç³»ç»Ÿä¾èµ–
```bash
# å®‰è£… ffmpegï¼ˆå¿…éœ€ï¼‰
brew install ffmpeg

# å®‰è£… Pythonï¼ˆå¯é€‰ï¼Œå¦‚æœä½¿ç”¨ç³»ç»Ÿ Pythonï¼‰
brew install python@3.11
```

### 3. é…ç½® Python ç¯å¢ƒ
**æ¨èä½¿ç”¨ condaï¼š**
```bash
# ä¸‹è½½å¹¶å®‰è£… Minicondaï¼ˆå¦‚æœæ²¡æœ‰ï¼‰
curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-arm64.sh
bash Miniconda3-latest-MacOSX-arm64.sh

# åˆ›å»ºä¸“ç”¨ç¯å¢ƒ
conda create -n whisper-app python=3.11 -y
conda activate whisper-app
```

### 4. å®‰è£… PyTorchï¼ˆé‡è¦ï¼šé€‰æ‹©æ­£ç¡®ç‰ˆæœ¬ï¼‰
```bash
# Apple Silicon Mac (M1/M2/M3) - æ”¯æŒ MPS åŠ é€Ÿ
pip install torch torchvision torchaudio

# Intel Mac - CPU ç‰ˆæœ¬
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
```

### 5. å…‹éš†é¡¹ç›®å¹¶å®‰è£…ä¾èµ–
```bash
git clone https://github.com/lemon5227/Auto-Subtitle-on-Generative-AI.git
cd Auto-Subtitle-on-Generative-AI

# å®‰è£…åº”ç”¨ä¾èµ–
pip install -r requirements.txt
```

### 6. å¯åŠ¨åº”ç”¨
```bash
# ä½¿ç”¨è·¨å¹³å°å¯åŠ¨å™¨ï¼ˆæ¨èï¼‰
python start.py

# æˆ–ç›´æ¥å¯åŠ¨
python app.py
```

### 7. è®¿é—®åº”ç”¨
- ä¸»ç•Œé¢ï¼šhttp://127.0.0.1:5001/app.html
- å®æ—¶è½¬å½•ï¼šhttp://127.0.0.1:5001/realtime.html

### macOS æ€§èƒ½ä¼˜åŒ–å»ºè®®

**Apple Silicon Mac (M1/M2/M3)ï¼š**
- âœ… è‡ªåŠ¨ä½¿ç”¨ MPS (Metal Performance Shaders) GPU åŠ é€Ÿ
- æ¨èæ¨¡å‹ï¼š`large-v3-turbo` (16GB+ RAM) æˆ– `small` (8GB RAM)
- é¢„æœŸæ€§èƒ½ï¼š2-3x å®æ—¶è½¬å½•é€Ÿåº¦

**Intel Macï¼š**
- ä½¿ç”¨ CPU æ¨¡å¼ï¼Œæ€§èƒ½è¾ƒæ…¢ä½†ç¨³å®š
- æ¨èæ¨¡å‹ï¼š`base` æˆ– `distil-small.en`
- å»ºè®®ä½¿ç”¨è¾ƒå°çš„éŸ³é¢‘åˆ†å—ä»¥å‡å°‘å†…å­˜ä½¿ç”¨

### æ•…éšœæ’é™¤
- **ffmpeg æœªæ‰¾åˆ°**ï¼š`brew install ffmpeg`
- **PyTorch MPS ä¸å¯ç”¨**ï¼šç¡®ä¿ä½¿ç”¨ macOS 12.3+ å’Œæœ€æ–°ç‰ˆ PyTorch
- **å†…å­˜ä¸è¶³**ï¼šä½¿ç”¨æ›´å°çš„æ¨¡å‹æˆ–å‡å°‘æ‰¹å¤„ç†å¤§å°
- **æ¨¡å‹ä¸‹è½½å¤±è´¥**ï¼šæ£€æŸ¥ç½‘ç»œè¿æ¥å’Œç£ç›˜ç©ºé—´ï¼ˆè‡³å°‘ 5GBï¼‰

è¯¦ç»†çš„ macOS é…ç½®è¯´æ˜è¯·å‚è€ƒï¼š[README.macOS.md](README.macOS.md)
<!-- Language selector: default is English. Click a link to switch. -->
<p align="right">Language: <strong>English</strong> | <a href="README.zh-CN.md">ä¸­æ–‡</a></p>

# Auto-Subtitle-on-Generative-AI â€” English (Full)

Short description

This is a demo project for local subtitle generation and translation. It combines speech recognition (Whisper-style models) with translation models (from Hugging Face). The app supports extracting audio from local files or remote videos (e.g., YouTube), producing VTT subtitles, and optionally translating those subtitles into a target language. A lightweight web UI is included for uploads, downloads, model management and subtitle preview.

Key features:
- Fetch videos (background jobs) from URLs or use local files
- Transcribe audio into VTT using Whisper models
- Translate subtitles using translation models (optional bilingual output)
- Model management UI for downloading/removing models

Requirements

System-level:
- ffmpeg (for audio extraction and transcode)

Python dependencies (see `requirements.txt`):
- Flask
- openai-whisper or faster-whisper (optional)
- torch (choose the correct wheel for your platform/CUDA)
- transformers
- sentencepiece
- huggingface-hub
- yt-dlp

Note about faster-whisper:
- `faster-whisper` is an alternative implementation that can be significantly faster and more memory-efficient than `openai-whisper`, especially when using GPU. It uses optimized decoders and can leverage CUDA more effectively.
- To install faster-whisper (optional):

```bash
pip install faster-whisper
```

Usage note: when using `faster-whisper`, adapt the server-side transcription code to import and call its API. The repository supports selecting `use_faster` in the frontend which you should wire to your server-side handler to enable faster-whisper if available.

## ğŸ macOS Quick Setup Guide

### System Requirements
- macOS 10.15+ (recommended macOS 12+)
- Python 3.8+ (recommended Python 3.11)
- At least 8GB RAM (recommended 16GB+)

### 1. Install Homebrew (if not installed)
```bash
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
```

### 2. Install System Dependencies
```bash
# Install ffmpeg (required)
brew install ffmpeg

# Install Python (optional, if using system Python)
brew install python@3.11
```

### 3. Setup Python Environment
**Recommended using conda:**
```bash
# Download and install Miniconda (if not installed)
curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-arm64.sh
bash Miniconda3-latest-MacOSX-arm64.sh

# Create dedicated environment
conda create -n whisper-app python=3.11 -y
conda activate whisper-app
```

### 4. Install PyTorch (Important: Choose correct version)
```bash
# Apple Silicon Mac (M1/M2/M3) - MPS acceleration support
pip install torch torchvision torchaudio

# Intel Mac - CPU version
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
```

### 5. Clone and Install Dependencies
```bash
git clone https://github.com/lemon5227/Auto-Subtitle-on-Generative-AI.git
cd Auto-Subtitle-on-Generative-AI

# Install application dependencies
pip install -r requirements.txt
```

### 6. Launch Application
```bash
# Use cross-platform launcher (recommended)
python start.py

# Or launch directly
python app.py
```

### 7. Access Application
- Main Interface: http://127.0.0.1:5001/app.html
- Real-time Transcription: http://127.0.0.1:5001/realtime.html

### macOS Performance Optimization

**Apple Silicon Mac (M1/M2/M3):**
- âœ… Automatic MPS (Metal Performance Shaders) GPU acceleration
- Recommended models: `large-v3-turbo` (16GB+ RAM) or `small` (8GB RAM)
- Expected performance: 2-3x real-time transcription speed

**Intel Mac:**
- CPU mode, slower but stable performance
- Recommended models: `base` or `distil-small.en`
- Suggest using smaller audio chunks to reduce memory usage

For detailed macOS configuration instructions, see: [README.macOS.md](README.macOS.md)

## Quick start

1) Clone repository

```bash
git clone https://github.com/lemon5227/Auto-Subtitle-on-Generative-AI.git
cd Auto-Subtitle-on-Generative-AI
```

2) Recommended: use conda (preferred)

If you use conda, the following steps will create an environment, install system-level packages (ffmpeg) from conda-forge, and install Python dependencies. Conda is recommended because it simplifies installing PyTorch and matching CUDA toolkits.

```bash
# create and activate conda env
conda create -n aitype python=3.11 -y
conda activate aitype

# install ffmpeg from conda-forge
conda install -c conda-forge ffmpeg -y

# install pytorch (CPU example) via conda (replace with appropriate cudatoolkit for GPU)
conda install pytorch torchvision torchaudio cpuonly -c pytorch -y

# install other python deps
pip install -r requirements.txt
```

Notes on PyTorch/GPU: For GPU support, pick the correct conda command from https://pytorch.org/ (select your OS, package manager=conda, and CUDA version). Example (GPU, CUDA 11.8):

```bash
conda install pytorch torchvision torchaudio cudatoolkit=11.8 -c pytorch -c nvidia -y
```

If you prefer a plain venv instead of conda, you can still use:

```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

3) Start the app

```bash
python3 app.py
```

Visit: http://127.0.0.1:5001/

Front-end quick workflow

1. Upload a local video file or paste a YouTube link and click Fetch (background download).
2. After download completes, the video will be available in the player. Click Generate to start transcription (choose model/options).
3. The UI will show VTT subtitles; you can edit, translate, and download them.

Backend API (reference)

- POST /fetch -> start background download, returns video_id
- GET /fetch/status?video_id=... -> check download status and server path
- POST /upload -> upload a local file
- POST /extract_async -> start transcription job (payload: { video_path, model, use_faster, language })
- GET /extract/status?job_id=... -> check transcription job status / result
- POST /translate -> translate VTT content (payload: { vtt_content, source_lang, target_lang, video_path })
- GET /models/status, POST /models/download, POST /models/delete -> model management

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜
- **ffmpeg æœªæ‰¾åˆ°**: å®‰è£…ç³»ç»Ÿ ffmpeg (`brew install ffmpeg` / `apt install ffmpeg`)
- **æ¨¡å‹ä¸‹è½½å¤±è´¥**: æ£€æŸ¥ç£ç›˜ç©ºé—´ï¼ˆè‡³å°‘ 5GBï¼‰å’Œç½‘ç»œè¿æ¥
- **è½¬å½•é€Ÿåº¦æ…¢**: ä½¿ç”¨æ›´å°çš„æ¨¡å‹æˆ– GPU åŠ é€Ÿ
- **å†…å­˜ä¸è¶³**: å‡å°‘æ‰¹å¤„ç†å¤§å°æˆ–ä½¿ç”¨ CPU ä¼˜åŒ–æ¨¡å¼

### æ€§èƒ½åŸºå‡†
| è®¾å¤‡ç±»å‹ | æ¨¡å‹ | é¢„æœŸé€Ÿåº¦ | æ¨èé…ç½® |
|----------|------|----------|----------|
| RTX 4090 | large-v3-turbo | ~5-8x å®æ—¶ | 24GB VRAM |
| RTX 3060 | large-v3-turbo | ~3-5x å®æ—¶ | 12GB VRAM |
| M2 Max | large-v3-turbo | ~2-3x å®æ—¶ | 32GB RAM |
| M1 | small | ~3-4x å®æ—¶ | 16GB RAM |
| CPU (Intel) | base | ~1-2x å®æ—¶ | 16GB RAM |

## ğŸ¤ è´¡çŒ®æŒ‡å—

æˆ‘ä»¬æ¬¢è¿ PR å’Œ Issueï¼å¦‚æœéœ€è¦é›†æˆå…¶ä»–æ¨¡å‹ï¼ˆWhisperXã€è‡ªå®šä¹‰ç¿»è¯‘æ¨¡å‹ï¼‰ï¼Œè¯·å¼€ Issue è¯¦ç»†æè¿°æ‚¨çš„ç¯å¢ƒå’Œéœ€æ±‚ã€‚

### å¼€å‘ç¯å¢ƒ
```bash
# å…‹éš†ä»“åº“
git clone https://github.com/lemon5227/Auto-Subtitle-on-Generative-AI.git
cd Auto-Subtitle-on-Generative-AI

# å®‰è£…å¼€å‘ä¾èµ–
pip install -r requirements.txt
pip install black flake8 pytest  # ä»£ç æ ¼å¼å’Œæµ‹è¯•

# è¿è¡Œæµ‹è¯•
python test_turbo.py
```

## ğŸ“„ è®¸å¯å’Œæ³¨æ„äº‹é¡¹

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚è¯·ç¡®ä¿éµå®ˆç¬¬ä¸‰æ–¹æ¨¡å‹/æœåŠ¡çš„æ¡æ¬¾ï¼ˆHugging Faceã€YouTubeï¼‰ã€‚ç”¨äºç”Ÿäº§ç¯å¢ƒæ—¶ï¼Œè¯·è€ƒè™‘è®¿é—®æ§åˆ¶ã€è®¸å¯åˆè§„å’Œå®‰å…¨åŠ å›ºã€‚

## â­ è‡´è°¢

- [OpenAI Whisper](https://github.com/openai/whisper) - è¯­éŸ³è¯†åˆ«æ¨¡å‹
- [Hugging Face Transformers](https://github.com/huggingface/transformers) - æ¨¡å‹æ¡†æ¶
- [FunASR](https://github.com/alibaba-damo-academy/FunASR) - SenseVoice æ”¯æŒ
- [faster-whisper](https://github.com/guillaumekln/faster-whisper) - æ€§èƒ½ä¼˜åŒ–

---

<p align="center">
  å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ª â­ Starï¼
</p>
