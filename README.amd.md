# AMD ç¬”è®°æœ¬éƒ¨ç½²æŒ‡å—

ä¸“ä¸º AMD GPU ç¬”è®°æœ¬ç”¨æˆ·è®¾è®¡çš„ AI å­—å¹•ç”Ÿæˆå™¨å®Œæ•´éƒ¨ç½²æ–¹æ¡ˆã€‚

## ðŸŽ® AMD GPU æ”¯æŒè¯´æ˜Ž

### AMD GPU æž¶æž„æ”¯æŒ
- âœ… **RDNA2/RDNA3**: RX 6000/7000 ç³»åˆ— (æŽ¨è)
- âœ… **RDNA**: RX 5000 ç³»åˆ— (è‰¯å¥½æ”¯æŒ)  
- âš ï¸ **GCN**: RX 400/500 ç³»åˆ— (æœ‰é™æ”¯æŒ)
- âœ… **APU**: Ryzen é›†æ˜¾ (åŸºç¡€æ”¯æŒ)

### ç³»ç»Ÿè¦æ±‚
- **æ“ä½œç³»ç»Ÿ**: Linux (Ubuntu 20.04+, æŽ¨è22.04) 
- **å†…å­˜**: è‡³å°‘ 8GB RAM (æŽ¨è 16GB+)
- **å­˜å‚¨**: è‡³å°‘ 20GB å¯ç”¨ç©ºé—´
- **ç½‘ç»œ**: ç¨³å®šè¿žæŽ¥ç”¨äºŽæ¨¡åž‹ä¸‹è½½

## ðŸš€ AMD ä¸“ç”¨ä¸€é”®éƒ¨ç½²

### æ–¹æ³•ä¸€ï¼šAMD ä¼˜åŒ–å®‰è£…è„šæœ¬

```bash
# AMD ç¬”è®°æœ¬ä¸“ç”¨ä¸€é”®å®‰è£…
curl -fsSL https://raw.githubusercontent.com/lemon5227/Auto-Subtitle-on-Generative-AI/main/install-amd.sh | bash
```

### æ–¹æ³•äºŒï¼šæ‰‹åŠ¨è¯¦ç»†éƒ¨ç½²

#### æ­¥éª¤ 1: ç³»ç»Ÿå‡†å¤‡

**æ›´æ–°ç³»ç»ŸåŒ…:**
```bash
sudo apt update && sudo apt upgrade -y
```

**å®‰è£…åŸºç¡€ä¾èµ–:**
```bash
sudo apt install -y \
    python3 python3-pip python3-venv \
    git curl wget \
    ffmpeg \
    build-essential \
    software-properties-common \
    dkms
```

#### æ­¥éª¤ 2: AMD GPU é©±åŠ¨å®‰è£…

**æ£€æŸ¥ AMD GPU ä¿¡æ¯:**
```bash
lspci | grep -i amd
lsmod | grep amdgpu
```

**å®‰è£… AMD GPU é©±åŠ¨:**
```bash
# Ubuntu å®˜æ–¹é©±åŠ¨ (æŽ¨è)
sudo apt install -y mesa-vulkan-drivers xserver-xorg-video-amdgpu

# æˆ–å®‰è£… AMD å®˜æ–¹é©±åŠ¨
wget https://repo.radeon.com/amdgpu-install/22.40.5/ubuntu/jammy/amdgpu-install_5.4.50405-1_all.deb
sudo dpkg -i amdgpu-install_5.4.50405-1_all.deb
sudo apt update
sudo apt install -y amdgpu-dkms
```

#### æ­¥éª¤ 3: ROCm å¹³å°å®‰è£… (GPU åŠ é€Ÿ)

**æ·»åŠ  ROCm ä»“åº“:**
```bash
# æ·»åŠ  ROCm APT ä»“åº“
wget -qO - https://repo.radeon.com/rocm/rocm.gpg.key | sudo apt-key add -
echo 'deb [arch=amd64] https://repo.radeon.com/rocm/apt/5.7/ jammy main' | sudo tee /etc/apt/sources.list.d/rocm.list
sudo apt update
```

**å®‰è£… ROCm:**
```bash
# æ ¸å¿ƒ ROCm ç»„ä»¶
sudo apt install -y rocm-dev rocm-libs hip-dev

# æ·»åŠ ç”¨æˆ·åˆ° render ç»„
sudo usermod -a -G render,video $USER

# é‡æ–°ç™»å½•æˆ–é‡å¯ä»¥åº”ç”¨ç»„æƒé™
```

**éªŒè¯ ROCm å®‰è£…:**
```bash
# æ£€æŸ¥ ROCm ä¿¡æ¯
/opt/rocm/bin/rocminfo

# æ£€æŸ¥è®¾å¤‡
ls /dev/kfd /dev/dri/render*
```

#### æ­¥éª¤ 4: Python çŽ¯å¢ƒé…ç½®

**åˆ›å»ºè™šæ‹ŸçŽ¯å¢ƒ:**
```bash
cd ~
git clone https://github.com/lemon5227/Auto-Subtitle-on-Generative-AI.git
cd Auto-Subtitle-on-Generative-AI

# ä½¿ç”¨ venv
python3 -m venv venv_amd
source venv_amd/bin/activate

# æˆ–ä½¿ç”¨ conda
# conda create -n whisper-amd python=3.11 -y
# conda activate whisper-amd
```

#### æ­¥éª¤ 5: PyTorch ROCm ç‰ˆæœ¬å®‰è£…

**å®‰è£… PyTorch ROCm ç‰ˆæœ¬:**
```bash
# ROCm 5.7 å¯¹åº”çš„ PyTorch ç‰ˆæœ¬
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7

# éªŒè¯ ROCm æ”¯æŒ
python -c "
import torch
print(f'PyTorch version: {torch.__version__}')
print(f'ROCm available: {torch.cuda.is_available()}')  # ROCm ä½¿ç”¨ cuda API
if torch.cuda.is_available():
    print(f'GPU count: {torch.cuda.device_count()}')
    print(f'GPU name: {torch.cuda.get_device_name(0)}')
"
```

#### æ­¥éª¤ 6: åº”ç”¨ä¾èµ–å®‰è£…

```bash
# å®‰è£…åº”ç”¨ä¾èµ–
pip install -r requirements.txt

# AMD ä¼˜åŒ–çš„é¢å¤–ä¾èµ–
pip install accelerate optimum[onnxruntime]
```

## ðŸ”§ AMD ç‰¹æ®Šé…ç½®

### çŽ¯å¢ƒå˜é‡ä¼˜åŒ–

åˆ›å»º AMD ä¸“ç”¨å¯åŠ¨è„šæœ¬:
```bash
cat > start_amd.py << 'EOF'
#!/usr/bin/env python3
"""
AMD GPU ä¸“ç”¨å¯åŠ¨è„šæœ¬ - AI å­—å¹•ç”Ÿæˆå™¨
ðŸŽ® é’ˆå¯¹ AMD GPU å’Œ ROCm å¹³å°ä¼˜åŒ–
"""
import os
import sys
import subprocess

def setup_amd_environment():
    """é…ç½® AMD GPU ä¼˜åŒ–çŽ¯å¢ƒ"""
    print("ðŸŽ® AMD GPU ä¼˜åŒ–å¯åŠ¨å™¨")
    print("ðŸš€ ROCm å¹³å° AI å­—å¹•ç”Ÿæˆå™¨")
    print("=" * 50)
    
    # AMD GPU ä¼˜åŒ–çŽ¯å¢ƒå˜é‡
    amd_env = {
        # ROCm è®¾ç½®
        'HSA_OVERRIDE_GFX_VERSION': '10.3.0',  # å…¼å®¹æ€§è®¾ç½®
        'ROCM_PATH': '/opt/rocm',
        'HIP_VISIBLE_DEVICES': '0',  # ä½¿ç”¨ç¬¬ä¸€ä¸ª GPU
        
        # PyTorch ä¼˜åŒ–
        'PYTORCH_HIP_ALLOC_CONF': 'max_split_size_mb:128',
        'TOKENIZERS_PARALLELISM': 'false',
        
        # å†…å­˜ä¼˜åŒ–
        'OMP_NUM_THREADS': '4',
        'MKL_NUM_THREADS': '4',
        
        # AMD GPU ç‰¹å®šä¼˜åŒ–
        'AMD_LOG_LEVEL': '1',
        'HIP_LAUNCH_BLOCKING': '0',
    }
    
    for key, value in amd_env.items():
        os.environ[key] = value
        print(f"   {key}={value}")
    
    print("\nðŸ” æ£€æŸ¥ AMD GPU æ”¯æŒ...")
    check_amd_gpu()

def check_amd_gpu():
    """æ£€æŸ¥ AMD GPU çŽ¯å¢ƒ"""
    try:
        import torch
        print(f"   PyTorch: {torch.__version__}")
        
        # æ£€æŸ¥ ROCm/HIP æ”¯æŒ
        gpu_available = torch.cuda.is_available()
        print(f"   GPU å¯ç”¨: {'âœ… æ˜¯' if gpu_available else 'âŒ å¦'}")
        
        if gpu_available:
            print(f"   GPU æ•°é‡: {torch.cuda.device_count()}")
            print(f"   GPU åç§°: {torch.cuda.get_device_name(0)}")
            
            # ç®€å• GPU æµ‹è¯•
            try:
                x = torch.randn(100, 100).cuda()
                y = torch.matmul(x, x)
                print("   GPU æµ‹è¯•: âœ… é€šè¿‡")
                del x, y
                torch.cuda.empty_cache()
            except Exception as e:
                print(f"   GPU æµ‹è¯•: âŒ å¤±è´¥ - {e}")
        else:
            print("   ðŸ’¡ å°†ä½¿ç”¨ CPU æ¨¡å¼")
            
    except ImportError:
        print("   âŒ PyTorch æœªå®‰è£…")

def start_application():
    """å¯åŠ¨åº”ç”¨"""
    print("\nðŸŒ å¯åŠ¨ AI å­—å¹•ç”Ÿæˆå™¨...")
    print("   ðŸ“º å®žæ—¶è½¬å½•: http://localhost:5001/realtime.html")
    print("   ðŸŽ¬ æ–‡ä»¶å¤„ç†: http://localhost:5001/app.html")
    print("\nðŸ”” æ™ºèƒ½GPUé€‚é…æç¤º:")
    print("   - ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹AMD/NVIDIA/Apple GPU")
    print("   - AMD GPUéœ€è¦ROCmæ”¯æŒï¼Œæ— ROCmä¼šå›žé€€CPUæ¨¡å¼")
    print("   - å¤§æ¨¡åž‹å¯èƒ½éœ€è¦ 8GB+ æ˜¾å­˜")
    print("   - æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
    print("\n" + "-" * 50)
    
    try:
        subprocess.run([sys.executable, "app.py"], check=True)
    except KeyboardInterrupt:
        print("\nðŸ‘‹ æœåŠ¡å·²åœæ­¢")
    except Exception as e:
        print(f"\nâŒ å¯åŠ¨å¤±è´¥: {e}")
        print("\nðŸ’¡ é€šç”¨GPUæ•…éšœæŽ’é™¤:")
        print("   1. æ£€æŸ¥ä¾èµ–: pip install -r requirements.txt")
        print("   2. AMDç”¨æˆ·: ç¡®ä¿ROCmå·²å®‰è£…")
        print("   3. NVIDIAç”¨æˆ·: æ£€æŸ¥CUDAé©±åŠ¨")
        print("   4. å¼ºåˆ¶CPUæ¨¡å¼: export CUDA_VISIBLE_DEVICES=-1")
        print("   5. ä½¿ç”¨æ™ºèƒ½å¯åŠ¨å™¨: python start_smart.py")

if __name__ == "__main__":
    setup_amd_environment()
    start_application()
EOF

chmod +x start_amd.py
```

### GPU å†…å­˜ç®¡ç†

**åˆ›å»º AMD ä¸“ç”¨é…ç½®:**
```bash
# AMD GPU å†…å­˜é…ç½®
echo 'export HSA_OVERRIDE_GFX_VERSION=10.3.0' >> ~/.bashrc
echo 'export ROCM_PATH=/opt/rocm' >> ~/.bashrc
echo 'export PATH=$ROCM_PATH/bin:$PATH' >> ~/.bashrc
source ~/.bashrc
```

## ðŸ” éªŒè¯å’Œæµ‹è¯•

### å®Œæ•´çŽ¯å¢ƒæ£€æŸ¥
```bash
# åˆ›å»ºæ£€æŸ¥è„šæœ¬
cat > check_amd_env.py << 'EOF'
#!/usr/bin/env python3
"""AMD GPU çŽ¯å¢ƒå®Œæ•´æ£€æŸ¥è„šæœ¬"""

import os
import subprocess
import sys

def check_system():
    print("ðŸ–¥ï¸ ç³»ç»Ÿä¿¡æ¯æ£€æŸ¥")
    print("-" * 30)
    
    # æ£€æŸ¥ AMD GPU
    try:
        result = subprocess.run(['lspci'], capture_output=True, text=True)
        amd_gpus = [line for line in result.stdout.split('\n') if 'AMD' in line and ('VGA' in line or 'Display' in line)]
        if amd_gpus:
            print("âœ… AMD GPU æ£€æµ‹:")
            for gpu in amd_gpus:
                print(f"   {gpu.strip()}")
        else:
            print("âŒ æœªæ£€æµ‹åˆ° AMD GPU")
    except:
        print("âŒ GPU æ£€æŸ¥å¤±è´¥")
    
    # æ£€æŸ¥ ROCm
    rocm_path = '/opt/rocm'
    if os.path.exists(rocm_path):
        print(f"âœ… ROCm å®‰è£…è·¯å¾„: {rocm_path}")
        
        # æ£€æŸ¥ rocminfo
        try:
            result = subprocess.run([f'{rocm_path}/bin/rocminfo'], 
                                  capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                print("âœ… rocminfo å¯ç”¨")
            else:
                print("âš ï¸ rocminfo æ‰§è¡Œå¼‚å¸¸")
        except:
            print("âŒ rocminfo ä¸å¯ç”¨")
    else:
        print("âŒ ROCm æœªå®‰è£…")

def check_pytorch():
    print("\nðŸ”¥ PyTorch ROCm æ£€æŸ¥")
    print("-" * 30)
    
    try:
        import torch
        print(f"âœ… PyTorch: {torch.__version__}")
        print(f"âœ… CUDA/ROCm: {'å¯ç”¨' if torch.cuda.is_available() else 'ä¸å¯ç”¨'}")
        
        if torch.cuda.is_available():
            print(f"ðŸŽ® GPU æ•°é‡: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                print(f"   GPU {i}: {torch.cuda.get_device_name(i)}")
        
        # ç®€å•æµ‹è¯•
        if torch.cuda.is_available():
            try:
                x = torch.randn(1000, 1000)
                x_gpu = x.cuda()
                result = torch.matmul(x_gpu, x_gpu)
                print("âœ… GPU è®¡ç®—æµ‹è¯•: é€šè¿‡")
                del x, x_gpu, result
                torch.cuda.empty_cache()
            except Exception as e:
                print(f"âŒ GPU è®¡ç®—æµ‹è¯•: å¤±è´¥ - {e}")
    except ImportError:
        print("âŒ PyTorch æœªå®‰è£…")
    except Exception as e:
        print(f"âŒ PyTorch æ£€æŸ¥å¤±è´¥: {e}")

def check_dependencies():
    print("\nðŸ“¦ ä¾èµ–æ£€æŸ¥")
    print("-" * 30)
    
    deps = ['flask', 'whisper', 'torch', 'transformers']
    for dep in deps:
        try:
            __import__(dep)
            print(f"âœ… {dep}")
        except ImportError:
            print(f"âŒ {dep} æœªå®‰è£…")

if __name__ == "__main__":
    print("ðŸŽ® AMD GPU AI å­—å¹•ç”Ÿæˆå™¨ - çŽ¯å¢ƒæ£€æŸ¥")
    print("=" * 60)
    check_system()
    check_pytorch()
    check_dependencies()
    print("\n" + "=" * 60)
    print("ðŸ’¡ å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒ AMD éƒ¨ç½²æŒ‡å—è¿›è¡Œæ•…éšœæŽ’é™¤")
EOF

python check_amd_env.py
```

## ðŸš¨ å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### Q1: ROCm æ£€æµ‹ä¸åˆ° GPU
```bash
# æ£€æŸ¥å†…æ ¸æ¨¡å—
lsmod | grep amdgpu

# é‡æ–°åŠ è½½é©±åŠ¨
sudo modprobe -r amdgpu
sudo modprobe amdgpu

# æ£€æŸ¥è®¾å¤‡æƒé™
ls -la /dev/kfd /dev/dri/render*
```

### Q2: PyTorch æ— æ³•ä½¿ç”¨ GPU
```bash
# æ£€æŸ¥ ROCm çŽ¯å¢ƒå˜é‡
echo $ROCM_PATH
echo $HSA_OVERRIDE_GFX_VERSION

# é‡æ–°å®‰è£… ROCm ç‰ˆ PyTorch
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7
```

### Q3: å†…å­˜ä¸è¶³é”™è¯¯
```bash
# å‡å°‘å†…å­˜ä½¿ç”¨
export PYTORCH_HIP_ALLOC_CONF=max_split_size_mb:64
export HSA_OVERRIDE_GFX_VERSION=10.3.0

# ä½¿ç”¨è¾ƒå°æ¨¡åž‹
# åœ¨åº”ç”¨ä¸­é€‰æ‹© base æˆ– small æ¨¡åž‹
```

### Q4: æ€§èƒ½è¾ƒæ…¢
```bash
# ç¡®ä¿ä½¿ç”¨é«˜æ€§èƒ½æ¨¡å¼
echo performance | sudo tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor

# æ£€æŸ¥ GPU é¢‘çŽ‡
sudo cat /sys/class/drm/card0/device/pp_dpm_sclk
```

## ðŸŽ¯ AMD æ€§èƒ½ä¼˜åŒ–å»ºè®®

### ç¡¬ä»¶é…ç½®æŽ¨è
- **æœ€ä½³**: RX 6700 XT / RX 7800 XT (12GB+ æ˜¾å­˜)
- **æŽ¨è**: RX 6600 XT / RX 7600 (8GB æ˜¾å­˜)  
- **å¯ç”¨**: RX 5500 XT / APU (4GB+ æ˜¾å­˜)

### è½¯ä»¶é…ç½®ä¼˜åŒ–
```bash
# åˆ›å»ºæ€§èƒ½é…ç½®è„šæœ¬
cat > optimize_amd.sh << 'EOF'
#!/bin/bash
# AMD GPU æ€§èƒ½ä¼˜åŒ–è„šæœ¬

echo "ðŸš€ åº”ç”¨ AMD GPU æ€§èƒ½ä¼˜åŒ–..."

# CPU è°ƒåº¦å™¨ä¼˜åŒ–
echo performance | sudo tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor

# GPU ç”µæºç®¡ç†
echo high | sudo tee /sys/class/drm/card0/device/power_dpm_force_performance_level

# å†…å­˜ä¼˜åŒ–
echo 1 | sudo tee /proc/sys/vm/drop_caches

echo "âœ… AMD ä¼˜åŒ–å®Œæˆ"
EOF

chmod +x optimize_amd.sh
```

## ðŸŒŸ å¯åŠ¨åº”ç”¨

### ä½¿ç”¨ AMD ä¼˜åŒ–å¯åŠ¨å™¨
```bash
# æ¿€æ´»çŽ¯å¢ƒ
source venv_amd/bin/activate  # æˆ– conda activate whisper-amd

# è¿›å…¥é¡¹ç›®ç›®å½•
cd ~/Auto-Subtitle-on-Generative-AI

# å¯åŠ¨ AMD ä¼˜åŒ–ç‰ˆæœ¬
python start_amd.py
```

### è®¿é—®åº”ç”¨
- **å®žæ—¶è½¬å½•**: http://localhost:5001/realtime.html
- **æ–‡ä»¶å¤„ç†**: http://localhost:5001/app.html

---

ðŸŽ® **AMD ç¬”è®°æœ¬ç”¨æˆ·ä¸“äº«çš„ AI å­—å¹•ç”Ÿæˆå™¨éƒ¨ç½²å®Œæˆï¼** ðŸš€