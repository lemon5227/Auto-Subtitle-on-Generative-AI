# requirements.txt for Auto-Subtitle-on-Generative-AI
#
# Cross-platform installation notes:
#
# PYTORCH INSTALLATION:
# - Linux/Windows: Follow PyTorch.org instructions for CUDA/CPU
# - macOS Apple Silicon: pip install torch torchvision torchaudio (supports MPS)
# - macOS Intel: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
#
# FFMPEG (System dependency):
# - Ubuntu/Debian: sudo apt install ffmpeg
# - macOS: brew install ffmpeg  
# - Windows: Download from ffmpeg.org and add to PATH
# - Conda (all platforms): conda install ffmpeg
#
# GPU ACCELERATION:
# - Linux/Windows: CUDA support with appropriate drivers
# - macOS Apple Silicon: Automatic MPS (Metal Performance Shaders) support
# - faster-whisper: CUDA only (Linux/Windows)

Flask>=2.0
Flask-SocketIO>=5.0
python-socketio>=5.0
python-engineio>=4.0
openai-whisper
transformers>=4.37.0
accelerate
sentencepiece
huggingface-hub
opencc-python-reimplemented
# FunASR for SenseVoice support
torchaudio
funasr
yt-dlp
numpy

# Optional but recommended for much faster transcription on supported hardware
# Install only if your platform supports it and you meet its requirements
faster-whisper

# Qwen LLM for intelligent subtitle refinement (optional)
# Download models from Hugging Face:
# - Qwen/Qwen2.5-3B-Instruct (recommended, ~6GB)
# - Qwen/Qwen2.5-7B-Instruct (high quality, ~14GB)
# - Qwen/Qwen2.5-1.5B-Instruct (lightweight, ~3GB)
# If not installed, the system will fall back to rule-based refinement
# Install with: pip install transformers>=4.37.0

# Utilities
tqdm

# Optional / deployment
gunicorn
python-dotenv
