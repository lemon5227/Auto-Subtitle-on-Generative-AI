# 翻译功能更新说明

## 修复内容

### 1. 修复 `CURRENT_QWEN_MODEL` 未定义错误
- 在全局变量区添加 `CURRENT_QWEN_MODEL = None`
- 初始化为 None，在需要时动态设置

### 2. 优化模型名称映射
- 支持短名称：`qwen3-0.6b`, `qwen3-1.7b`, `qwen3-4b`, `qwen3-8b`
- 支持完整ID：`Qwen/Qwen3-0.6B`, `Qwen/Qwen3-1.7B`, 等
- 自动映射和fallback机制

### 3. 翻译模式说明

#### 实时翻译（Realtime）
- **特点**：自动翻译每条字幕，快速响应
- **推荐模型**：
  - `Qwen3-0.6B` (0.6B) - 最快，适合低配置 ⚡
  - `Qwen3-1.7B` (1.7B) - 推荐，速度质量平衡 ⭐
- **使用场景**：会议记录、实时字幕、快速预览

#### 精细翻译（Refined）
- **特点**：点击字幕后翻译，使用更大模型
- **推荐模型**：
  - `Qwen3-4B` (4B) - 平衡，大多数场景 ⭐
  - `Qwen3-8B` (8B) - 最佳质量，专业翻译 🎯
  - `Helsinki-NLP` - 传统翻译模型fallback
- **使用场景**：专业翻译、高质量要求、最终输出

### 4. 不勾选Qwen时的翻译逻辑
- 默认使用 **Helsinki-NLP** 翻译模型
- 支持的翻译对：
  - 中文 ↔ 英语
  - 英语 → 日语、韩语、西班牙语、法语、德语
  - 其他常见语言对
- 如果Helsinki模型不支持，自动fallback到Qwen（如果可用）

## UI改进建议

### 简化后的高级设置面板

```
🎯 高级功能
  └─ 🌐 翻译功能 [✓]                    [🔧 模型管理]
       ├─ 目标语言: [选择语言 ▼]
       ├─ 翻译模式:
       │    ⚡ 实时翻译 (轻量模型)  - 自动翻译，快速响应
       │    🎯 精细翻译 (高质量)    - 点击翻译，质量优先 [✓]
       │
       └─ 精细翻译模型: [Qwen3-4B ▼]
            💡 精细模式可使用大模型，翻译更准确自然

  └─ ✨ 字幕优化 (ASR纠错) [  ]
       ├─ 优化模型: [Qwen3-4B ▼]
       └─ 💡 使用AI模型修正语音识别错误
```

### 模型管理（点击按钮后展开）

```
🔧 已安装的模型                    [🔄 刷新]
  ├─ Qwen3-1.7B  [✓ 已下载] [🗑️ 删除]
  ├─ Qwen3-4B    [✓ 已下载] [🗑️ 删除]
  └─ Qwen3-8B    [⬇ 50%]    [❌ 取消]

[📥 下载新模型]  管理Qwen翻译模型
```

## 性能对比

| 模型 | 大小 | 速度 | 质量 | 显存 | 推荐场景 |
|------|------|------|------|------|----------|
| Qwen3-0.6B | 0.6B | ⚡⚡⚡⚡ | ⭐⭐ | 2GB | 实时翻译 |
| Qwen3-1.7B | 1.7B | ⚡⚡⚡ | ⭐⭐⭐ | 4GB | 实时翻译（推荐）|
| Qwen3-4B | 4B | ⚡⚡ | ⭐⭐⭐⭐ | 8GB | 精细翻译（推荐）|
| Qwen3-8B | 8B | ⚡ | ⭐⭐⭐⭐⭐ | 16GB | 专业翻译 |
| Helsinki-NLP | - | ⚡⚡⚡ | ⭐⭐⭐ | 1GB | Fallback |

## 测试步骤

1. **测试实时翻译**
   ```
   - 勾选"翻译功能"
   - 选择"实时翻译"
   - 选择模型：Qwen3-1.7B
   - 开始监听，说话
   - 应该自动显示原文和译文分屏
   ```

2. **测试精细翻译**
   ```
   - 勾选"翻译功能"
   - 选择"精细翻译"
   - 选择模型：Qwen3-4B
   - 开始监听，说话
   - 字幕旁有🌐按钮，点击后翻译
   ```

3. **测试Helsinki fallback**
   ```
   - 勾选"翻译功能"
   - 不勾选使用Qwen
   - 应该使用Helsinki-NLP模型
   ```

## 注意事项

⚠️ **警告信息说明**
```
Using `chunk_length_s` is very experimental with seq2seq models...
```
这是Whisper模型的正常警告，不影响功能。可以在代码中添加 `ignore_warning=True` 来忽略。

## 代码改进

### 忽略Whisper警告
```python
# 在加载Whisper pipeline时添加
pipe = pipeline(
    "automatic-speech-recognition",
    model=model_name,
    chunk_length_s=30,
    ignore_warning=True  # 忽略实验性警告
)
```
